<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CapCut-Like Video Editor - Beat Sync Prototype</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background: #f0f0f0; }
        .container { max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        input[type="file"] { margin: 10px 0; }
        button { background: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; margin: 5px; }
        button:hover { background: #0056b3; }
        #preview { width: 100%; max-width: 640px; height: 360px; border: 1px solid #ccc; background: black; margin: 20px 0; }
        #waveform { width: 100%; height: 100px; border: 1px solid #ccc; margin: 10px 0; }
        .status { color: #666; font-style: italic; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Beat-Synced Video Editor (CapCut-Inspired Prototype)</h1>
        <p>Upload a video and audio. Click "Sync & Edit" for one-click beat detection, cuts, and movements (zooms/pans).</p>
        
        <div>
            <label>Upload Video (MP4):</label><br>
            <input type="file" id="videoInput" accept="video/*">
        </div>
        
        <div>
            <label>Upload Audio (MP3/WAV):</label><br>
            <input type="file" id="audioInput" accept="audio/*">
        </div>
        
        <button id="syncBtn">Analyze Beats & Sync (One-Click Edit)</button>
        <button id="downloadBtn" disabled>Download Edited Video</button>
        
        <div id="status" class="status">Ready to upload files.</div>
        
        <canvas id="waveform"></canvas>
        <video id="preview" controls></video>
    </div>

    <script>
        const videoInput = document.getElementById('videoInput');
        const audioInput = document.getElementById('audioInput');
        const syncBtn = document.getElementById('syncBtn');
        const downloadBtn = document.getElementById('downloadBtn');
        const status = document.getElementById('status');
        const waveformCanvas = document.getElementById('waveform');
        const previewVideo = document.getElementById('preview');
        
        let originalVideo = null;
        let audioBuffer = null;
        let beats = []; // Array of beat timestamps (seconds)
        let editedVideoBlob = null;
        let mediaRecorder = null;
        
        // Load video
        videoInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) {
                originalVideo = URL.createObjectURL(file);
                status.textContent = 'Video loaded. Upload audio next.';
            }
        });
        
        // Load and analyze audio for beats
        audioInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (file) {
                status.textContent = 'Analyzing audio...';
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                const response = await fetch(URL.createObjectURL(file));
                const arrayBuffer = await response.arrayBuffer();
                audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
                
                // Simple beat detection: Analyze waveform for peaks (threshold-based)
                const channelData = audioBuffer.getChannelData(0);
                const sampleRate = audioBuffer.sampleRate;
                const beats = detectBeats(channelData, sampleRate);
                window.beats = beats; // Global for access
                drawWaveform(channelData, waveformCanvas);
                status.textContent = `Audio loaded. Detected ${beats.length} beats.`;
            }
        });
        
        // Simple beat detection function (threshold on amplitude peaks)
        function detectBeats(channelData, sampleRate) {
            const beats = [];
            const bufferLength = channelData.length;
            const beatThreshold = 0.2; // Adjust for sensitivity
            const minBeatInterval = 0.3; // Seconds between beats (e.g., min 120 BPM)
            let lastBeatTime = 0;
            
            for (let i = 0; i < bufferLength; i += sampleRate * 0.1) { // Step by 0.1s
                let sum = 0;
                for (let j = 0; j < sampleRate * 0.1; j++) {
                    if (i + j < bufferLength) sum += Math.abs(channelData[i + j]);
                }
                const avg = sum / (sampleRate * 0.1);
                const time = i / sampleRate;
                
                if (avg > beatThreshold && (time - lastBeatTime) > minBeatInterval) {
                    beats.push(time);
                    lastBeatTime = time;
                }
            }
            return beats;
        }
        
        // Draw simple waveform
        function drawWaveform(channelData, canvas) {
            const ctx = canvas.getContext('2d');
            const width = canvas.width = canvas.offsetWidth;
            const height = canvas.height;
            ctx.clearRect(0, 0, width, height);
            
            const sliceWidth = width / channelData.length;
            let x = 0;
            for (let i = 0; i < channelData.length; i++) {
                const v = channelData[i] * height / 2;
                const y = height / 2 + v;
                
                if (i % Math.floor(channelData.length / width) === 0) {
                    ctx.lineTo(x, y);
                    ctx.stroke();
                    x += sliceWidth;
                    ctx.beginPath();
                    ctx.moveTo(x, height / 2);
                }
            }
        }
        
        // One-click sync: Cut video at beats, add movements (zoom/pan via canvas)
        syncBtn.addEventListener('click', async () => {
            if (!originalVideo || !window.beats || window.beats.length === 0) {
                status.textContent = 'Upload video and audio first.';
                return;
            }
            
            status.textContent = 'Syncing video to beats... This may take a moment.';
            previewVideo.src = originalVideo;
            await previewVideo.load();
            
            // Create edited video using Canvas (simulate cuts and movements)
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = 640;
            canvas.height = 360;
            
            const stream = canvas.captureStream(30); // 30 FPS
            mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=vp9' });
            const chunks = [];
            mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
            mediaRecorder.onstop = () => {
                editedVideoBlob = new Blob(chunks, { type: 'video/webm' });
                downloadBtn.disabled = false;
                status.textContent = 'Edit complete! Preview below.';
                previewVideo.src = URL.createObjectURL(editedVideoBlob);
            };
            mediaRecorder.start();
            
            let currentTime = 0;
            const duration = previewVideo.duration;
            const beatClips = []; // For cuts
            
            // Define cuts: Split video into clips between beats
            for (let i = 0; i < window.beats.length; i++) {
                const start = window.beats[i];
                const end = (window.beats[i + 1] || duration) - 0.1; // 0.1s overlap for smooth
                if (end > start) beatClips.push({ start, end });
            }
            
            // Render loop: Play clips with movements (zoom/pan)
            function renderFrame() {
                if (mediaRecorder.state !== 'recording') return;
                
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                const clipIndex = Math.floor(currentTime / (duration / beatClips.length));
                const clip = beatClips[clipIndex] || beatClips[beatClips.length - 1];
                
                if (currentTime >= clip.end) {
                    currentTime = clip.start; // Loop clip for sync
                }
                
                // Draw video frame at current time
                previewVideo.currentTime = Math.max(clip.start, Math.min(currentTime, clip.end));
                ctx.drawImage(previewVideo, 0, 0, canvas.width, canvas.height);
                
                // Add movement: Simple zoom/pan based on beat position
                const beatProgress = (currentTime - clip.start) / (clip.end - clip.start);
                const zoom = 1 + Math.sin(beatProgress * Math.PI * 2) * 0.2; // Oscillate zoom
                const panX = Math.sin(beatProgress * Math.PI) * 50; // Pan left/right
                ctx.save();
                ctx.translate(panX, 0);
                ctx.scale(zoom, zoom);
                ctx.drawImage(previewVideo, -canvas.width / 2, -canvas.height / 2, canvas.width, canvas.height);
                ctx.restore();
                
                currentTime += 1/30; // 30 FPS
                if (currentTime < duration) {
                    requestAnimationFrame(renderFrame);
                } else {
                    mediaRecorder.stop();
                }
            }
            renderFrame();
        });
        
        // Download edited video
        downloadBtn.addEventListener('click', () => {
            if (editedVideoBlob) {
                const url = URL.createObjectURL(editedVideoBlob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'synced-video.webm';
                a.click();
                URL.revokeObjectURL(url);
            }
        });
    </script>
</body>
</html>            editedVideoBlob = await applyEdits(originalVideo, beats);

            // Step 5: Preview and show final duration
            const preview = document.getElementById('preview');
            preview.src = URL.createObjectURL(editedVideoBlob);
            preview.style.display = 'block';
            preview.onloadedmetadata = () => {
                const finalDuration = preview.duration;
                document.getElementById('timingInfo').innerHTML = `Final video duration: ${Math.round(finalDuration)} seconds (original: ${Math.round(originalDuration)}s)`;
            };
            document.getElementById('downloadBtn').style.display = 'inline-block';
            document.getElementById('status').style.display = 'none';
        }

        // Helper: Convert file to Blob URL
        function videoToBlob(file) {
            return new Promise((resolve) => {
                const reader = new FileReader();
                reader.onload = () => resolve(new Blob([reader.result], { type: file.type }));
                reader.readAsArrayBuffer(file);
            });
        }

        function audioToBlob(file) {
            return new Promise((resolve) => {
                const reader = new FileReader();
                reader.onload = () => resolve(new Blob([reader.result], { type: file.type }));
                reader.readAsArrayBuffer(file);
            });
        }

        // Simulate audio extraction (placeholder; use FFmpeg for real)
        async function extractAudioFromVideo(videoBlob) {
            // For demo, return a dummy audio blob (in production, use ffmpeg -i input.mp4 -vn audio.wav)
            await ffmpeg.writeFile('input.mp4', await videoBlob.arrayBuffer());
            await ffmpeg.exec(['-i', 'input.mp4', '-vn', 'audio.wav']);
            const data = await ffmpeg.readFile('audio.wav');
            return new Blob([data.buffer], { type: 'audio/wav' });
        }

        // Basic beat detection using Web Audio API (simplified frequency analysis)
        async function detectBeats(audioBlob) {
            const audioContext = new AudioContext();
            const arrayBuffer = await audioBlob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            const data = audioBuffer.getChannelData(0); // Mono channel

            const beats = [];
            let lastBeat = 0;
            for (let i = 0; i < data.length; i += 1024) { // Sample every 1024 frames (~0.02s at 48kHz)
                const chunk = data.slice(i, i + 1024);
                const energy = chunk.reduce((a, b) => a + b * b, 0); // RMS energy
                if (energy > 0.01 && (i / audioContext.sampleRate - lastBeat) > 0.5) { // Threshold and min interval
                    beats.push(i / audioContext.sampleRate);
                    lastBeat = i / audioContext.sampleRate;
                }
            }
            return beats.slice(0, 5); // Limit to 5 beats for demo
        }

        // Apply edits: Trim video into segments at beats, add zoom/pan (simulated via FFmpeg filters)
        async function applyEdits(videoBlob, beats) {
            const inputName = 'input.mp4';
            await ffmpeg.writeFile(inputName, await videoBlob.arrayBuffer());

            // For demo: Concat simple trims (e.g., cut every 2s, add zoom filter)
            let filterComplex = 'split=3[a][b][c]; [a]scale=iw*1.1:ih*1.1,zoompan=z=\'zoom+0.001\':d=125 [zoomed];';
            beats.forEach((beat, index) => {
                filterComplex += `[b]trim=start=${beat}:duration=2,setpts=PTS-STARTPTS [cut${index}];`;
            });
            filterComplex += `[zoomed][cut0]overlay=0:0 [out];`; // Basic overlay for movement

            await ffmpeg.exec(['-i', inputName, '-filter_complex', filterComplex, '-map', '[out]', 'output.mp4']);
            const data = await ffmpeg.readFile('output.mp4');
            return new Blob([data.buffer], { type: 'video/mp4' });
        }

        function downloadVideo() {
            if (editedVideoBlob) {
                const url = URL.createObjectURL(editedVideoBlob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'edited-video.mp4';
                a.click();
            }
        }
    </script>
</body>
    </html>
